{
 "metadata": {
  "name": "qlc Wiki Leipzig"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Use a Wikipedia corpus to extract semantic similarities\n",
      "\n",
      "In this tutorial we will use a Wikipedia corpus to extract semantically similar words for a given word. We will use a technique called \"Latent Semantic Analysis\" (LSA) that we apply onto a collocation matrix extracted from the [Bavarian Wikipedia](http://bar.wikipedia.org/wiki/Hoamseitn). I used the ideas from the paper of Widdows and Dorow (2002) \"[Visualisation Techniques for Analysing Meaning](http://www.puttypeg.net/papers/visualising-meaning.pdf)\" for this tutorial. The data was prepared with the help of the [Wikipedia Extractor](http://medialab.di.unipi.it/wiki/Wikipedia_Extractor), which is probably the easiest way to extract a pure text corpus from the Wikipedia dumps. The dump contains all kind of markup used in Wikipedia that we need to remove before we can process the data. This was already done and the data was transformed to [LAF/GrAF](http://www.iso.org/iso/catalogue_detail.htm?csnumber=37326). We will use a Python GrAF parser to read the data. For most of the calculation we will use [numpy](http://www.numpy.org/) and [scipy](http://scipy.org/). Finally, [matplotlib](http://matplotlib.org/) will be used to visualize the space of semantic similarities."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Prerequisites"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%cd c:/Users/Peter/Documents/Corpora/leipzig"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "c:\\Users\\Peter\\Documents\\Corpora\\leipzig\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "import io\n",
      "import math\n",
      "import codecs\n",
      "\n",
      "import xml.etree.ElementTree as ET\n",
      "\n",
      "import numpy as np\n",
      "import nltk\n",
      "import scipy.sparse.linalg"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stopwords = nltk.corpus.stopwords.words(\"Spanish\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class LSA(object):\n",
      "\n",
      "    def __init__(self, stopwords, ignorechars):\n",
      "        self.stopwords = stopwords\n",
      "        self.wdict = {}\n",
      "        self.dcount = 0\n",
      "        self.top_words = []\n",
      "        \n",
      "    def _words_for_document(self, doc):\n",
      "        words = doc.split()\n",
      "        words2 = list()\n",
      "\n",
      "        for w in words:\n",
      "            w = re.sub(u\"[{0}]\".format(ignorechars), \"\", w.lower())\n",
      "\n",
      "            if not w or w in self.stopwords:\n",
      "                continue\n",
      "            \n",
      "            words2.append(w)\n",
      "    \n",
      "        return words2\n",
      "    \n",
      "\n",
      "    def add_words_for_doc(self, doc):\n",
      "        for w in self._words_for_document(doc):\n",
      "            if w in self.wdict:\n",
      "                self.wdict[w].append(self.dcount)\n",
      "\n",
      "            else:\n",
      "                self.wdict[w] = [self.dcount]\n",
      "\n",
      "        self.dcount += 1\n",
      "    \n",
      "    def pre_process(self):\n",
      "        self.top_words = [w for w, _ in sorted(self.wdict.iteritems(), key=lambda(k,v): len(v))][-1000:]\n",
      "        self.keys = [k for k in self.wdict.keys() if len(self.wdict[k]) > 2]\n",
      "        self.keys.sort()\n",
      "        self.keys_indices = { w: i for i, w in enumerate(self.keys) }\n",
      "        self.A = np.zeros([len(self.keys), len(self.top_words)])\n",
      "\n",
      "    def process(self, doc):\n",
      "        words = self._words_for_document(doc)\n",
      "        len_words = len(words) - 1\n",
      "        for i, w in enumerate(words):\n",
      "            for j, t in enumerate(self.top_words):\n",
      "                if w != t:\n",
      "                    start = i - 15\n",
      "                    if i < 0:\n",
      "                        start = 0\n",
      "                    end = len_words\n",
      "                    if end > i + 15:\n",
      "                        end = i + 15\n",
      "                    if t in words[start:end] and w in self.keys_indices:\n",
      "                        self.A[self.keys_indices[w],j] += 1\n",
      "\n",
      "    def normalize(self):\n",
      "        WordsPerTop = np.sum(self.A, axis=0)\n",
      "        TopsPerWord = np.sum(np.asarray(self.A > 0, 'i'), axis=1)\n",
      "        rows, cols = self.A.shape\n",
      "        for i in range(rows):\n",
      "            for j in range(cols):\n",
      "                if WordsPerTop[j] == 0 or TopsPerWord[i] == 0:\n",
      "                    self.A[i,j] = 0\n",
      "                else:\n",
      "                    self.A[i,j] = (self.A[i,j] / WordsPerTop[j]) * math.log(float(cols) / TopsPerWord[i])\n",
      "\n",
      "    def calc(self, k=100):\n",
      "        self.U, self.S, self.Vt = scipy.sparse.linalg.svds(self.A, k)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gp = graf.GraphParser()\n",
      "g = gp.parse(\"text.hdr\")\n",
      "\n",
      "text = codecs.open(\"text.txt\", \"r\", \"utf-8\")\n",
      "txt = text.read()\n",
      "text.close()\n",
      "\n",
      "documents = list()\n",
      "for n in g.nodes:\n",
      "    if n.id.startswith(\"doc\"):\n",
      "        doc = txt[n.links[0][0].start:n.links[0][0].end]\n",
      "        documents.append(doc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mylsa = LSA(stopwords, ignorechars)\n",
      "\n",
      "for d in documents:\n",
      "\tmylsa.add_words_for_doc(d)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mylsa.pre_process()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for d in documents:\n",
      "\tmylsa.process(d)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mylsa.normalize()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mylsa.calc(100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy.linalg\n",
      "reconstructedMatrix = np.dot(np.dot(mylsa.U, scipy.linalg.diagsvd(mylsa.S,len(mylsa.S),len(mylsa.S))), mylsa.Vt)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy.spatial\n",
      "tree = scipy.spatial.cKDTree(reconstructedMatrix)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "neighbours = tree.query(reconstructedMatrix[mylsa.keys.index(u\"bia\")], k=100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "subset = reconstructedMatrix[neighbours[1]]\n",
      "words = [mylsa.keys[i] for i in neighbours[1]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tempU, tempS, tempVt = scipy.linalg.svd(subset)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pylab.plot(tempS)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 40,
       "text": [
        "[<matplotlib.lines.Line2D at 0x13398dd8>]"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "coords = tempU[:,1:3]\n",
      "pylab.figure(1, figsize=(16,12))\n",
      "pylab.plot(tempU[:,1], tempU[:,2], marker=\"o\", linestyle=\"None\")\n",
      "for label, x, y in zip(words, tempU[:,1], tempU[:,2]):\n",
      "    pylab.annotate(\n",
      "        label, \n",
      "        xy = (x, y), xytext = (-5, 5),\n",
      "        textcoords = 'offset points', ha = 'right', va = 'bottom',\n",
      "        bbox = dict(boxstyle = 'round,pad=0.5', fc = 'yellow', alpha = 0.5))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 148
    }
   ],
   "metadata": {}
  }
 ]
}