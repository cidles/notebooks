{
 "metadata": {
  "name": "",
  "signature": "sha256:7280039a9835495463ebf094e9cc64f690148b2384da04141aed39e1570e4a34"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 0. Loading the data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The data was exported from an Excel file, in Open Office, with \"Save As\"->\"Text CSV\", as \"UTF-8\", \"{Tabulator}\" as field seperator and double quotes (\") as text seperator."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload\n",
      "%autoreload 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import helpers.diana\n",
      "\n",
      "tier_numbers = {\n",
      "    \"clause_id\": 2,\n",
      "    \"clause_type\": 3,\n",
      "    \"grammatical_relation\": 4,\n",
      "    \"pos_agreement\": 5,\n",
      "    \"last_line\": 7\n",
      "}\n",
      "ag = helpers.diana.from_excel(\"data/Hinuq3.csv\", tier_numbers=tier_numbers)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Error: duplicate clause ID: #228\n",
        "Error: duplicate clause ID: #404\n",
        "Error: duplicate clause ID: #1273"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Error: duplicate clause ID: #1601\n",
        "Error: duplicate clause ID: #1682\n",
        "Error: duplicate clause ID: #\n",
        "Error: duplicate clause ID: #\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 1. Linear order"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import collections\n",
      "\n",
      "verbs = [ 'COP', 'SAY', 'v.tr', 'v.intr', 'v.aff' ]\n",
      "verb_map = { v: \"V\" for v in verbs}\n",
      "others = [ 'A', 'S', 'P', 'EXP', 'STIM', 'zero-A', 'zero-S', 'zero-P', 'zero-EXP', 'zero-STIM' ]\n",
      "search_terms = verbs + others\n",
      "\n",
      "word_orders = collections.defaultdict(int)\n",
      "word_orders_ids = collections.defaultdict(list)\n",
      "\n",
      "for wo in helpers.diana.word_orders(ag, search_terms):\n",
      "    word_orders[tuple(wo.word_order)] += 1\n",
      "    word_orders_ids[tuple(wo.word_order)].append(wo.clause_id)\n",
      "\n",
      "for word_order, count in word_orders.items():\n",
      "    print(\"{0} => {1}\".format(word_order, count))\n",
      "    if count < 5:\n",
      "        print(\"    {1}\".format(word_order, word_orders_ids[word_order]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('STIM', 'COP') => 1\n",
        "    ['clause_id..n#1532']\n",
        "('zero-A', 'zero-P', 'v.tr') => 90\n",
        "('zero-A', 'P') => 1\n",
        "    ['clause_id..n#1013']\n",
        "('STIM', 'EXP', 'v.aff') => 6\n",
        "('v.aff', 'STIM', 'EXP') => 1\n",
        "    ['clause_id..n#1603']\n",
        "('v.tr', 'A', 'P') => 10\n",
        "('zero-A', 'v.tr', 'zero-P') => 1\n",
        "    ['clause_id..n#200']\n",
        "('SAY', 'A') => 31\n",
        "('zero-S', 'v.intr') => 267\n",
        "('v.intr',) => 5\n",
        "('EXP', 'STIM', 'v.aff') => 26\n",
        "('zero-EXP', 'zero-STIM', 'v.aff') => 15\n",
        "('COP', 'S') => 33\n",
        "('P', 'A') => 1\n",
        "    ['clause_id..n#713']\n",
        "('P', 'v.tr') => 2\n",
        "    ['clause_id..n#1678', 'clause_id..n#1762']\n",
        "('zero-EXP', 'v.aff', 'STIM') => 8\n",
        "('v.intr', 'S') => 135\n",
        "('S',) => 2\n",
        "    ['clause_id..n#1396', 'clause_id..n#285']\n",
        "('zero-A', 'P', 'v.intr') => 1\n",
        "    ['clause_id..n#1788']\n",
        "('zero-P', 'A', 'v.tr') => 4\n",
        "    ['clause_id..n#1518', 'clause_id..n#957', 'clause_id..n#1526', 'clause_id..n#1472']\n",
        "('EXP', 'P', 'v.aff') => 1\n",
        "    ['clause_id..n#649']\n",
        "('EXP', 'v.aff', 'zero-STIM') => 1\n",
        "    ['clause_id..n#1024']\n",
        "('zero-P', 'v.tr', 'A') => 4\n",
        "    ['clause_id..n#1465', 'clause_id..n#1375', 'clause_id..n#948', 'clause_id..n#265']\n",
        "('zero-EXP', 'STIM', 'v.aff') => 24\n",
        "('A', 'v.tr', 'P') => 39\n",
        "('zero-A', 'v.tr') => 3\n",
        "    ['clause_id..n#1496', 'clause_id..n#1598', 'clause_id..n#1255']\n",
        "('v.tr', 'P', 'A') => 3\n",
        "    ['clause_id..n#747', 'clause_id..n#798', 'clause_id..n#772']\n",
        "('zero-S', 'COP') => 2\n",
        "    ['clause_id..n#1087', 'clause_id..n#786']\n",
        "('zero-EXP', 'P', 'v.aff') => 2\n",
        "    ['clause_id..n#418', 'clause_id..n#508']\n",
        "('A', 'SAY') => 76\n",
        "('zero-A', 'v.tr', 'P') => 40\n",
        "('A', 'P', 'v.tr', 'A', 'SAY') => 1\n",
        "    ['clause_id..n#1268']\n",
        "('A', 'P', 'v.tr', 'zero-A', 'zero-P', 'v.tr') => 1\n",
        "    ['clause_id..n#1633']\n",
        "('P', 'A', 'v.tr') => 25\n",
        "('A', 'v.tr', 'zero-P') => 1\n",
        "    ['clause_id..n#1278']\n",
        "('STIM', 'v.aff', 'EXP') => 7\n",
        "('zero-S', 'v.intr', 'S', 'v.intr') => 1\n",
        "    ['clause_id..n#1117']\n",
        "('S', 'v.tr') => 1\n",
        "    ['clause_id..n#1673']\n",
        "('zero-S',) => 3\n",
        "    ['clause_id..n#1309', 'clause_id..n#1297', 'clause_id..n#1089']\n",
        "('A', 'v.tr') => 1\n",
        "    ['clause_id..n#1641']\n",
        "('zero-A', 'zero-P', 'v.tr', 'S', 'v.intr') => 1\n",
        "    ['clause_id..n#1037']\n",
        "('A', 'P', 'v.tr') => 105\n",
        "('EXP', 'zero-STIM', 'v.aff') => 9\n",
        "('v.aff', 'EXP', 'STIM') => 10\n",
        "('S', 'COP') => 92\n",
        "('SAY',) => 2\n",
        "    ['clause_id..n#1624', 'clause_id..n#231']\n",
        "('A',) => 10\n",
        "('S', 'v.intr') => 401\n",
        "('A', 'P', 'v.intr') => 3\n",
        "    ['clause_id..n#1759', 'clause_id..n#1819', 'clause_id..n#1580']\n",
        "('EXP', 'v.aff', 'STIM') => 19\n",
        "('zero-STIM', 'v.aff', 'EXP') => 4\n",
        "    ['clause_id..n#872', 'clause_id..n#41', 'clause_id..n#1663', 'clause_id..n#1225']\n",
        "('COP',) => 3\n",
        "    ['clause_id..n#478', 'clause_id..n#443', 'clause_id..n#187']\n",
        "() => 2\n",
        "    ['clause_id..n#327', 'clause_id..n#1080']\n",
        "('zero-A',) => 3\n",
        "    ['clause_id..n#1314', 'clause_id..n#1649', 'clause_id..n#1816']\n",
        "('P', 'v.tr', 'A') => 33\n",
        "('zero-A', 'SAY') => 18\n",
        "('zero-A', 'P', 'v.tr') => 246\n",
        "('A', 'zero-P', 'v.tr') => 24\n",
        "('v.tr', 'P') => 1\n",
        "    ['clause_id..n#1674']\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 1.1. Are subordinate clauses significantly more often verb-final than main clauses?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "word_orders_main = []\n",
      "word_orders_main_count = collections.defaultdict(int)\n",
      "word_orders_sub = []\n",
      "word_orders_sub_count = collections.defaultdict(int)\n",
      "main_clause_types = [ \"m\", \"m.rs\" ]\n",
      "sub_clause_types = [ \"sub\", \"sub.rs\" ]\n",
      "clause_types = main_clause_types + sub_clause_types\n",
      "search_terms = verbs + ['A', 'S', 'P', 'EXP', 'STIM']\n",
      "\n",
      "for wo in helpers.diana.word_orders(ag, search_terms, verb_map):\n",
      "    if \"V\" in wo.word_order and wo.clause_type in clause_types and len(wo.word_order) > 1:\n",
      "        if wo.clause_type in sub_clause_types:\n",
      "            word_orders_sub.append(wo.word_order)\n",
      "            word_orders_sub_count[tuple(wo.word_order)] += 1\n",
      "        else:\n",
      "            word_orders_main.append(wo.word_order)\n",
      "            word_orders_main_count[tuple(wo.word_order)] += 1 "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Statistical test"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Hypothesis H0: It does not depend on the clause type (sub vs. main) whether the clause unit is verb final."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "main_v_fin = 0; main_v_nonfin = 0; sub_v_fin = 0; sub_v_nonfin = 0;\n",
      "for wo, c in word_orders_main_count.items():\n",
      "    if wo[-1] == \"V\":\n",
      "        main_v_fin += c\n",
      "    else:\n",
      "        main_v_nonfin += c\n",
      "for wo, c in word_orders_sub_count.items():\n",
      "    if wo[-1] == \"V\":\n",
      "        sub_v_fin += c\n",
      "    else:\n",
      "        sub_v_nonfin += c\n",
      "cont_table = [ [main_v_fin, main_v_nonfin], [sub_v_fin, sub_v_nonfin] ]\n",
      "cont_table"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "[[716, 340], [340, 36]]"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy.stats\n",
      "oddsratio, pvalue = scipy.stats.fisher_exact(cont_table)\n",
      "pvalue"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "8.8745019129901875e-20"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We reject the null hypothesis, as the chances of getting a distribution as the observed one are p < 0.05. The clause type affects the verb \"finalness\". In this case subordinate clauses have a sifgnificant higher count of verb final word orders."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 1.2. How differ main clauses and subordinate clauses in their word orders?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here are are the basic counts:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"Counts for main clauses:\")\n",
      "for wo, c in word_orders_main_count.items():\n",
      "    print(\"{0} => {1}\".format(wo, c))\n",
      "print(\"\\nCounts for sub clauses:\")\n",
      "for wo, c in word_orders_sub_count.items():\n",
      "    print(\"{0} => {1}\".format(wo, c))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Counts for main clauses:\n",
        "('P', 'A', 'V') => 21\n",
        "('S', 'V') => 375\n",
        "('EXP', 'V') => 7\n",
        "('V', 'STIM', 'EXP') => 1\n",
        "('EXP', 'V', 'STIM') => 19\n",
        "('P', 'V', 'A') => 29\n",
        "('A', 'V', 'P') => 36\n",
        "('V', 'EXP') => 4\n",
        "('A', 'P', 'V', 'A', 'V') => 1\n",
        "('V', 'EXP', 'STIM') => 10\n",
        "('V', 'A', 'P') => 10\n",
        "('A', 'P', 'V') => 86\n",
        "('STIM', 'V') => 15\n",
        "('STIM', 'EXP', 'V') => 6\n",
        "('V', 'P') => 23\n",
        "('A', 'V') => 94\n",
        "('V', 'A') => 35\n",
        "('P', 'V') => 86\n",
        "('V', 'STIM') => 8\n",
        "('STIM', 'V', 'EXP') => 4\n",
        "('V', 'S') => 158\n",
        "('EXP', 'STIM', 'V') => 24\n",
        "('EXP', 'P', 'V') => 1\n",
        "('V', 'P', 'A') => 3\n",
        "\n",
        "Counts for sub clauses:\n",
        "('P', 'A', 'V') => 4\n",
        "('S', 'V') => 119\n",
        "('EXP', 'V') => 3\n",
        "('STIM', 'V') => 10\n",
        "('STIM', 'V', 'EXP') => 3\n",
        "('V', 'P') => 18\n",
        "('P', 'V', 'A') => 4\n",
        "('A', 'V') => 12\n",
        "('P', 'V') => 165\n",
        "('V', 'S', 'V') => 2\n",
        "('V', 'S') => 8\n",
        "('EXP', 'STIM', 'V') => 2\n",
        "('A', 'V', 'P') => 3\n",
        "('A', 'P', 'V') => 22\n",
        "('A', 'P', 'V', 'V') => 1\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 1.3. Where are G, BEN, G, TIME, LOC, ADD usually positioned? (e.g. before or after the verb)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "particles = [ 'G', 'BEN', 'TIME', 'LOC', 'ADD' ]\n",
      "pos_counts = [ [0, 0] for _ in particles ]\n",
      "search_terms = verbs + particles\n",
      "\n",
      "for wo in helpers.diana.word_orders(ag, search_terms, verb_map):\n",
      "    for i, p in enumerate(particles):\n",
      "        if \"V\" in wo.word_order and p in wo.word_order:\n",
      "            if wo.word_order.index(\"V\") < wo.word_order.index(p):\n",
      "                pos_counts[i][0] += 1\n",
      "            else:\n",
      "                pos_counts[i][1] += 1\n",
      "                \n",
      "for i, p in enumerate(particles):\n",
      "    print(p)\n",
      "    print(\"    Count after verb:  {0}\".format(pos_counts[i][0]))\n",
      "    print(\"    Count before verb: {0}\".format(pos_counts[i][1]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "G\n",
        "    Count after verb:  112\n",
        "    Count before verb: 250\n",
        "BEN\n",
        "    Count after verb:  16\n",
        "    Count before verb: 68\n",
        "TIME\n",
        "    Count after verb:  9\n",
        "    Count before verb: 96\n",
        "LOC\n",
        "    Count after verb:  27\n",
        "    Count before verb: 121\n",
        "ADD\n",
        "    Count after verb:  21\n",
        "    Count before verb: 31\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 1.4. In main clauses: are BEN arguments significantly more often positioned before the verb than after the verb?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "particles = [ 'BEN', 'G', 'ADD' ]\n",
      "pos_counts = [ [0, 0] for _ in particles ]\n",
      "search_terms = verbs + particles\n",
      "\n",
      "before = 0\n",
      "after = 0\n",
      "for wo in helpers.diana.word_orders(ag, search_terms, verb_map):\n",
      "    for i, p in enumerate(particles):\n",
      "        if wo.clause_type in main_clause_types and \"V\" in wo.word_order and p in wo.word_order:\n",
      "            if wo.word_order.index(\"V\") < wo.word_order.index(p):\n",
      "                pos_counts[i][0] += 1\n",
      "            else:\n",
      "                pos_counts[i][1] += 1\n",
      "\n",
      "for i, p in enumerate(particles):\n",
      "    print(p)\n",
      "    print(\"    Count after verb:  {0}\".format(pos_counts[i][0]))\n",
      "    print(\"    Count before verb: {0}\".format(pos_counts[i][1]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "BEN\n",
        "    Count after verb:  13\n",
        "    Count before verb: 54\n",
        "G\n",
        "    Count after verb:  102\n",
        "    Count before verb: 148\n",
        "ADD\n",
        "    Count after verb:  20\n",
        "    Count before verb: 27\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Statistical test\n",
      "\n",
      "I am using a binomial test here: http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.binom_test.html#scipy.stats.binom_test"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "part_sum = [ 0, 0 ]\n",
      "for i, p in enumerate(particles):\n",
      "    part_sum[0] += pos_counts[i][0]\n",
      "    part_sum[1] += pos_counts[i][1]\n",
      "    print(\"Test for '{0}'\".format(p))\n",
      "    print(scipy.stats.binom_test(pos_counts[i]))\n",
      "print(\"Test for 'BEN+G+ADD'\")\n",
      "print(scipy.stats.binom_test(part_sum))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Test for 'BEN'\n",
        "4.46583468018e-07\n",
        "Test for 'G'\n",
        "0.00433272423368\n",
        "Test for 'ADD'\n",
        "0.381693397663\n",
        "Test for 'BEN+G+ADD'\n",
        "9.55713495137e-07\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Except for \"ADD\" it is very unlikely that those counts are random. So the difference for \"BEN\" and \"G\" and \"BEN+G+ADD\" is significant."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 1.5. In main and sub clauses: Are BEN + G + ADD significantly more often occurring after the verb than A or P or LOC, A + P or A + P + LOC?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "particles = [ 'BEN', 'G', 'ADD', 'A', 'P', 'LOC' ]\n",
      "pos_counts = [ [0, 0] for _ in particles ]\n",
      "search_terms = verbs + particles\n",
      "\n",
      "before = 0\n",
      "after = 0\n",
      "for wo in helpers.diana.word_orders(ag, search_terms, verb_map):\n",
      "    for i, p in enumerate(particles):\n",
      "        if wo.clause_type in main_clause_types and \"V\" in wo.word_order and p in wo.word_order:\n",
      "            if wo.word_order.index(\"V\") < wo.word_order.index(p):\n",
      "                pos_counts[i][0] += 1\n",
      "            else:\n",
      "                pos_counts[i][1] += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Hypothesis H0: It does not depend on the grammatical relation type if a participant appears before or after the verb.\n",
      "\n",
      "For the test we use the Fisher exact test, as this test also works for small numbers (http://docs.scipy.org/doc/scipy-0.13.0/reference/generated/scipy.stats.fisher_exact.html)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### BEN + G + ADD vs. A"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "BEN_G_ADD = [ 0, 0 ]\n",
      "BEN_G_ADD[0] = pos_counts[0][0] + pos_counts[1][0] + pos_counts[2][0]\n",
      "BEN_G_ADD[1] = pos_counts[0][1] + pos_counts[1][1] + pos_counts[2][1]\n",
      "cont_table = [ BEN_G_ADD, pos_counts[3] ]\n",
      "cont_table"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "[[135, 229], [77, 238]]"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "oddsratio, pvalue = scipy.stats.fisher_exact(cont_table)\n",
      "pvalue"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "0.00047424843237602184"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We reject the null hpythesis H0 because p < 0.05. The grammatical relation type does have influence on whether a participant appears before or after the verb. In this case, A appears significantly more often before the verb then BEN + G + ADD."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### BEN + G + ADD vs. P"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pos_counts[0][0] + pos_counts[1][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "115"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "oddsratio, pvalue = scipy.stats.fisher_exact(cont_table)\n",
      "pvalue"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "0.00047424843237602184"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Again, we reject the null hypothesis because p < 0.05. P occurs more often before the verb then BEN + G + ADD."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### BEN + G + ADD vs. LOC"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cont_table = [ BEN_G_ADD, pos_counts[5] ]\n",
      "cont_table"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "[[135, 229], [26, 96]]"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "oddsratio, pvalue = scipy.stats.fisher_exact(cont_table)\n",
      "pvalue"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "0.0012476388009485225"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Again, we reject the null hypothesis because p < 0.05. LOC occurs more often before the verb then BEN + G + ADD."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### BEN + G + ADD vs. A + P"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "A_P = [ 0, 0 ]\n",
      "A_P[0] = pos_counts[3][0] + pos_counts[4][0]\n",
      "A_P[1] = pos_counts[3][1] + pos_counts[4][1]\n",
      "cont_table = [ BEN_G_ADD, A_P ]\n",
      "cont_table"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "[[135, 229], [149, 462]]"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "oddsratio, pvalue = scipy.stats.fisher_exact(cont_table)\n",
      "pvalue"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "3.1494316179110786e-05"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Again, we reject the null hypothesis because p < 0.05. A + P occurs more often before the verb then BEN + G + ADD."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### BEN + G + ADD vs. A + P + LOC"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "A_P_LOC = [ 0, 0 ]\n",
      "A_P_LOC[0] = pos_counts[3][0] + pos_counts[4][0] + pos_counts[5][0]\n",
      "A_P_LOC[1] = pos_counts[3][1] + pos_counts[4][1] + pos_counts[5][1]\n",
      "cont_table = [ BEN_G_ADD, A_P_LOC ]\n",
      "cont_table"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "[[135, 229], [175, 558]]"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "oddsratio, pvalue = scipy.stats.fisher_exact(cont_table)\n",
      "pvalue"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "6.8264927933869299e-06"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Again, we reject the null hypothesis because p < 0.05. A + P + LOC occurs more often before the verb then BEN + G + ADD."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 1.6. SAY: Does SAY have more often an overtly expressed A than all other transitive verbs?\n",
      "\n",
      "Hypothesis 1 (H0): It does not depend on the type of the verb (SAY vs. others) if the A is expressed ouvertly.\n",
      "\n",
      "For the test we use the Fisher exact test, as this test also works for small numbers (http://docs.scipy.org/doc/scipy-0.13.0/reference/generated/scipy.stats.fisher_exact.html)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "other_verbs = [ 'COP', 'v.tr', 'v.intr', 'v.aff' ]\n",
      "search_terms = other_verbs + [ 'SAY', 'A', 'zero-A' ]\n",
      "verb_map = { v: \"V\" for v in other_verbs }\n",
      "SAY_counts = [ 0, 0 ]\n",
      "others_counts = [ 0, 0 ]\n",
      "for wo in helpers.diana.word_orders(ag, search_terms, verb_map):\n",
      "    if 'SAY' in wo.word_order:\n",
      "        if 'A' in wo.word_order:\n",
      "            SAY_counts[0] += 1\n",
      "        elif 'zero-A' in wo.word_order:\n",
      "            SAY_counts[1] += 1\n",
      "    if 'V' in wo.word_order:\n",
      "        if 'A' in wo.word_order:\n",
      "            others_counts[0] += 1\n",
      "        elif 'zero-A' in wo.word_order:\n",
      "            others_counts[1] += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cont_table = [ SAY_counts, others_counts ]\n",
      "cont_table"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "[[108, 18], [254, 382]]"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "oddsratio, pvalue = scipy.stats.fisher_exact(cont_table)\n",
      "pvalue"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "2.7580817280520951e-22"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We reject the null hypothesis because p < 0.05. A is more often ouvert in SAY sentences than in any other sentence with other verb types."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 1.7. Does the A of say more often follow its verb than the A of all other transitive verbs?\n",
      "\n",
      "H0: It does not depend on the verb type (A vs. others) if A is before or after the verb."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "search_terms = other_verbs + [ 'SAY', 'A' ]\n",
      "SAY_counts = [ 0, 0 ]\n",
      "others_counts = [ 0, 0 ]\n",
      "for wo in helpers.diana.word_orders(ag, search_terms, verb_map):\n",
      "    if 'SAY' in wo.word_order and 'A' in wo.word_order:\n",
      "        if wo.word_order.index(\"SAY\") < wo.word_order.index(\"A\"):\n",
      "            SAY_counts[0] += 1\n",
      "        else:\n",
      "            SAY_counts[1] += 1\n",
      "    if \"V\" in wo.word_order and \"A\" in wo.word_order:\n",
      "        if wo.word_order.index(\"V\") < wo.word_order.index(\"A\"):\n",
      "            others_counts[0] += 1\n",
      "        else:\n",
      "            others_counts[1] += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cont_table = [ SAY_counts, others_counts ]\n",
      "cont_table"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "[[31, 77], [50, 204]]"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "oddsratio, pvalue = scipy.stats.fisher_exact(cont_table)\n",
      "pvalue"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "0.072859585496121426"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We cannot reject the null hypothesis as p > 0.05. There is no significant difference in SAY vs. other verb sentences between A before and after the verb."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 1.8. Does the overt A of SAY more often precede or follow the verb (and what are the frequencies)?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"A after SAY: {0}\".format(SAY_counts[0]))\n",
      "print(\"A before SAY: {0}\".format(SAY_counts[1]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "A after SAY: 31\n",
        "A before SAY: 77\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 2. Agreement"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 2.1. How frequent is agreement in texts (in main and subordinate clauses)?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "verbs = [ 'v.tr', 'v.intr', 'v.aff' ]\n",
      "agreements = [0, 0]; noagreements = [0, 0];\n",
      "for wo in helpers.diana.word_orders(ag, verbs, with_agreement = True):\n",
      "    for agr in wo.agreement:\n",
      "        if wo.clause_type in sub_clause_types:\n",
      "            if agr == \"noagr\":\n",
      "                noagreements[0] += 1\n",
      "            else:\n",
      "                agreements[0] += 1\n",
      "        else:\n",
      "            if agr == \"noagr\":\n",
      "                noagreements[1] += 1\n",
      "            else:\n",
      "                agreements[1] += 1\n",
      "\n",
      "print(\"I found {0} verbs with and {1} verbs without agreement.\".format(agreements[0]+agreements[1], noagreements[0]+noagreements[1]))\n",
      "print(\"In main clauses: I found {0} verbs with and {1} verbs without agreement.\".format(agreements[1], noagreements[1]))\n",
      "print(\"In sub clauses: I found {0} verbs with and {1} verbs without agreement.\".format(agreements[0], noagreements[0]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "no agreement annotation in clause unit clause_id..n#1099 for grammatical relation 'v.tr'\n",
        "no agreement annotation in clause unit clause_id..n#603 for grammatical relation 'v.tr'\n",
        "no agreement annotation in clause unit clause_id..n#1025 for grammatical relation 'v.tr'\n",
        "no agreement annotation in clause unit clause_id..n#1110 for grammatical relation 'v.tr'\n",
        "no agreement annotation in clause unit clause_id..n#621 for grammatical relation 'v.intr'\n",
        "no agreement annotation in clause unit clause_id..n#476 for grammatical relation 'v.tr'\n",
        "no agreement annotation in clause unit clause_id..n#1696 for grammatical relation 'v.tr'\n",
        "no agreement annotation in clause unit clause_id..n#1751 for grammatical relation 'v.intr'\n",
        "no agreement annotation in clause unit clause_id..n#1534 for grammatical relation 'v.tr'\n",
        "no agreement annotation in clause unit clause_id..n#1094 for grammatical relation 'v.tr'\n",
        "no agreement annotation in clause unit clause_id..n#1728 for grammatical relation 'v.tr'\n",
        "no agreement annotation in clause unit clause_id..n#1026 for grammatical relation 'v.tr'\n",
        "no agreement annotation in clause unit clause_id..n#1278 for grammatical relation 'v.tr'\n",
        "no agreement annotation in clause unit clause_id..n#1174 for grammatical relation 'v.intr'\n",
        "no agreement annotation in clause unit clause_id..n#914 for grammatical relation 'v.aff'"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "no agreement annotation in clause unit clause_id..n#1786 for grammatical relation 'v.intr'\n",
        "no agreement annotation in clause unit clause_id..n#1458 for grammatical relation 'v.intr'\n",
        "no agreement annotation in clause unit clause_id..n#1493 for grammatical relation 'v.tr'\n",
        "no agreement annotation in clause unit clause_id..n#1322 for grammatical relation 'v.intr'\n",
        "no agreement annotation in clause unit clause_id..n#1302 for grammatical relation 'v.intr'\n",
        "no agreement annotation in clause unit clause_id..n#1235 for grammatical relation 'v.intr'\n",
        "no agreement annotation in clause unit clause_id..n#460 for grammatical relation 'v.aff'\n",
        "no agreement annotation in clause unit clause_id..n#11 for grammatical relation 'v.tr'\n",
        "no agreement annotation in clause unit clause_id..n#1103 for grammatical relation 'v.intr'\n",
        "no agreement annotation in clause unit clause_id..n#1750 for grammatical relation 'v.intr'\n",
        "no agreement annotation in clause unit clause_id..n#1864 for grammatical relation 'v.intr'\n",
        "I found 1224 verbs with and 335 verbs without agreement.\n",
        "In main clauses: I found 815 verbs with and 216 verbs without agreement.\n",
        "In sub clauses: I found 409 verbs with and 119 verbs without agreement.\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 2.2. Do non-agreeing verbs occur more often with overtly expressed S or P or STIM arguments than agreeing verbs (because the agreement prefixes are enough to track the reference)?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Hypothesis H0: It does not depend on the verbal agreement if S (or P or STIM) arguments are expressed overtly."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "search_terms = verbs + [ 'S', 'P', 'STIM',  'zero-S', 'zero-P', 'zero-STIM' ]\n",
      "cont_table_S = [ [0, 0], [0, 0] ]\n",
      "cont_table_P = [ [0, 0], [0, 0] ]\n",
      "cont_table_STIM = [ [0, 0], [0, 0] ]\n",
      "cont_table_S_P_STIM =  [ [0, 0], [0, 0] ]\n",
      "for wo in helpers.diana.word_orders(ag, search_terms, with_agreement = True):\n",
      "    agreeing = 0\n",
      "    if len(wo.word_order) != len(wo.agreement):\n",
      "        continue\n",
      "    for i, w in enumerate(wo.word_order):\n",
      "        if w in verbs:\n",
      "            if wo.agreement[i] == \"noagr\":\n",
      "                agreeing = 1\n",
      "    if \"zero-S\" in wo.word_order:\n",
      "        cont_table_S[agreeing][0] += 1\n",
      "        cont_table_S_P_STIM[agreeing][0] += 1\n",
      "    elif \"S\" in wo.word_order:\n",
      "        cont_table_S[agreeing][1] += 1\n",
      "        cont_table_S_P_STIM[agreeing][1] += 1\n",
      "    if \"zero-P\" in wo.word_order:\n",
      "        cont_table_P[agreeing][0] += 1\n",
      "        cont_table_S_P_STIM[agreeing][0] += 1\n",
      "    elif \"P\" in wo.word_order:\n",
      "        cont_table_P[agreeing][1] += 1\n",
      "        cont_table_S_P_STIM[agreeing][1] += 1\n",
      "    if \"zero-STIM\" in wo.word_order:\n",
      "        cont_table_STIM[agreeing][0] += 1\n",
      "        cont_table_S_P_STIM[agreeing][0] += 1\n",
      "    elif \"STIM\" in wo.word_order:\n",
      "        cont_table_STIM[agreeing][1] += 1\n",
      "        cont_table_S_P_STIM[agreeing][1] += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "no agreement annotation in clause unit clause_id..n#1099 for grammatical relation 'P'\n",
        "no agreement annotation in clause unit clause_id..n#1099 for grammatical relation 'v.tr'\n",
        "no agreement annotation in clause unit clause_id..n#603 for grammatical relation 'v.tr'\n",
        "no agreement annotation in clause unit clause_id..n#1300 for grammatical relation 'S'\n",
        "no agreement annotation in clause unit clause_id..n#1025 for grammatical relation 'v.tr'\n",
        "no agreement annotation in clause unit clause_id..n#1110 for grammatical relation 'v.tr'\n",
        "no agreement annotation in clause unit clause_id..n#621 for grammatical relation 'v.intr'\n",
        "no agreement annotation in clause unit clause_id..n#476 for grammatical relation 'v.tr'\n",
        "no agreement annotation in clause unit clause_id..n#1696 for grammatical relation 'v.tr'\n",
        "no agreement annotation in clause unit clause_id..n#1751 for grammatical relation 'v.intr'\n",
        "no agreement annotation in clause unit clause_id..n#1534 for grammatical relation 'v.tr'\n",
        "no agreement annotation in clause unit clause_id..n#1094 for grammatical relation 'v.tr'\n",
        "no agreement annotation in clause unit clause_id..n#1728 for grammatical relation 'v.tr'\n",
        "no agreement annotation in clause unit clause_id..n#1728 for grammatical relation 'P'\n",
        "no agreement annotation in clause unit clause_id..n#1026 for grammatical relation 'P'\n",
        "no agreement annotation in clause unit clause_id..n#1026 for grammatical relation 'v.tr'\n",
        "no agreement annotation in clause unit clause_id..n#1069 for grammatical relation 'P'\n",
        "no agreement annotation in clause unit clause_id..n#1278 for grammatical relation 'v.tr'"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "no agreement annotation in clause unit clause_id..n#1174 for grammatical relation 'v.intr'\n",
        "no agreement annotation in clause unit clause_id..n#914 for grammatical relation 'v.aff'\n",
        "no agreement annotation in clause unit clause_id..n#1786 for grammatical relation 'v.intr'\n",
        "no agreement annotation in clause unit clause_id..n#1458 for grammatical relation 'v.intr'\n",
        "no agreement annotation in clause unit clause_id..n#1493 for grammatical relation 'v.tr'\n",
        "no agreement annotation in clause unit clause_id..n#1322 for grammatical relation 'S'\n",
        "no agreement annotation in clause unit clause_id..n#1322 for grammatical relation 'v.intr'\n",
        "no agreement annotation in clause unit clause_id..n#1302 for grammatical relation 'v.intr'\n",
        "no agreement annotation in clause unit clause_id..n#1235 for grammatical relation 'v.intr'\n",
        "no agreement annotation in clause unit clause_id..n#460 for grammatical relation 'v.aff'\n",
        "no agreement annotation in clause unit clause_id..n#11 for grammatical relation 'v.tr'"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "no agreement annotation in clause unit clause_id..n#1103 for grammatical relation 'v.intr'\n",
        "no agreement annotation in clause unit clause_id..n#987 for grammatical relation 'S'\n",
        "no agreement annotation in clause unit clause_id..n#1750 for grammatical relation 'v.intr'\n",
        "no agreement annotation in clause unit clause_id..n#1256 for grammatical relation 'P'\n",
        "no agreement annotation in clause unit clause_id..n#1864 for grammatical relation 'v.intr'\n"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Statistical test for S"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cont_table_S"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 45,
       "text": [
        "[[232, 583], [39, 71]]"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "oddsratio, pvalue = scipy.stats.fisher_exact(cont_table_S)\n",
      "pvalue"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 46,
       "text": [
        "0.14666489919967896"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We cannot reject the null hypothesis, because p > 0.05. It does not depend on the verbal agreement whether S is expressed overtly."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Statistical test for P"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cont_table_P"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 47,
       "text": [
        "[[68, 337], [54, 166]]"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "oddsratio, pvalue = scipy.stats.fisher_exact(cont_table_P)\n",
      "pvalue"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 48,
       "text": [
        "0.026172486461504624"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can reject the hypothesis as p < 0.05. It does depend on verbal agreement whether P is expressed overtly. P is more often expressed overtly when there is agreement on the verb."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Staistical test for STIM"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cont_table_STIM"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 49,
       "text": [
        "[[28, 97], [1, 3]]"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "oddsratio, pvalue = scipy.stats.fisher_exact(cont_table_STIM)\n",
      "pvalue"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 51,
       "text": [
        "1.0"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here it is not possible to calculate, as the number of non-agreements is too low. Practically all verbs that have a STIM argument show agreement, whether the argument is expressed or not."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Statistical test for S + P + STIM"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cont_table_S_P_STIM"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 52,
       "text": [
        "[[328, 1017], [94, 240]]"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "oddsratio, pvalue = scipy.stats.fisher_exact(cont_table_S_P_STIM)\n",
      "pvalue"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 53,
       "text": [
        "0.15920829086242955"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We cannot reject the hypothesis as p > 0.05. It does not depend on the verbal agreement whether S + P + STIM is expressed overtly."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 3. Arguments in \"v.aff\" vs. \"v.tr\" sentences: ouvert vs. zero"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Counts"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "v_tree = { \"v.aff\": collections.defaultdict(int), \"v.tr\": collections.defaultdict(int) }\n",
      "for wo in word_orders:\n",
      "    v = None\n",
      "    if \"v.tr\" in wo:\n",
      "        v = \"v.tr\"\n",
      "    if \"v.aff\" in wo:\n",
      "        v = \"v.aff\"\n",
      "    if v is not None:\n",
      "        wo2 = tuple([e for e in sorted(wo) if e != \"v.aff\" and e != \"v.tr\"])\n",
      "        v_tree[v][wo2] += word_orders[wo]\n",
      "\n",
      "for v in [\"v.aff\", \"v.tr\"]:\n",
      "    print(v)\n",
      "    for e in v_tree[v]:\n",
      "        print(\"{0} => {1}\".format(e, v_tree[v][e]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "v.aff\n",
        "('EXP', 'P') => 1\n",
        "('EXP', 'zero-STIM') => 14\n",
        "('STIM', 'zero-EXP') => 32\n",
        "('zero-EXP', 'zero-STIM') => 15\n",
        "('EXP', 'STIM') => 69\n",
        "('P', 'zero-EXP') => 2\n",
        "v.tr\n",
        "('A',) => 1\n",
        "('S', 'v.intr', 'zero-A', 'zero-P') => 1\n",
        "('zero-A',) => 3\n",
        "('zero-A', 'zero-P') => 91\n",
        "('A', 'P') => 215\n",
        "('P', 'zero-A') => 286\n",
        "('P',) => 3\n",
        "('A', 'zero-P') => 33\n",
        "('A', 'P', 'zero-A', 'zero-P') => 1\n",
        "('A', 'A', 'P', 'SAY') => 1\n",
        "('S',) => 1\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Statistical test for A/EXP"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Hypothesis 1 (H0): It does not depend on the type of the verb (\"v.tr\" vs. \"v.aff\") if the A/EXP is expressed ouvertly.\n",
      "\n",
      "For the test we use the Fisher exact test, as this test also works for small numbers (http://docs.scipy.org/doc/scipy-0.13.0/reference/generated/scipy.stats.fisher_exact.html)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy.stats\n",
      "cont_table = [\n",
      "    [ v_tree[\"v.aff\"][('EXP', 'zero-STIM')] + v_tree[\"v.aff\"][('EXP', 'STIM')],\n",
      "      v_tree[\"v.aff\"][('zero-EXP', 'zero-STIM')] + v_tree[\"v.aff\"][('STIM', 'zero-EXP')] ],\n",
      "    [ v_tree[\"v.tr\"][('A', 'P')] + v_tree[\"v.tr\"][('A', 'zero-P')], \n",
      "      v_tree[\"v.tr\"][('P', 'zero-A')] + v_tree[\"v.tr\"][('zero-A', 'zero-P')] ]\n",
      "]\n",
      "cont_table"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "[[83, 47], [248, 377]]"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "oddsratio, pvalue = scipy.stats.fisher_exact(cont_table)\n",
      "pvalue"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "5.6925858449569448e-07"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We reject the null hypothesis, as the chances of getting a distribution as the observed one are p < 0.05. The verb type affects the ouvertness of the A/EXP argument. In this case the \"v.aff\" sentences have sigificantly more ouvert arguments EXP then the \"v.tr\" sentences have ouvert A."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Statistical test for P/STIM"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Hypothesis 2 (H0): It does not depend on the type of the verb (\"v.tr\" vs. \"v.aff\") if the P/STIM is expressed ouvertly."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy.stats\n",
      "cont_table = [\n",
      "    [ v_tree[\"v.aff\"][('STIM', 'zero-EXP')] + v_tree[\"v.aff\"][('EXP', 'STIM')],\n",
      "      v_tree[\"v.aff\"][('zero-EXP', 'zero-STIM')] + v_tree[\"v.aff\"][('EXP', 'zero-STIM')] ],\n",
      "    [ v_tree[\"v.tr\"][('A', 'P')] + v_tree[\"v.tr\"][('P', 'zero-A')], \n",
      "      v_tree[\"v.tr\"][('A', 'zero-P')] + v_tree[\"v.tr\"][('zero-A', 'zero-P')] ]\n",
      "]\n",
      "cont_table"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 33,
       "text": [
        "[[101, 29], [501, 124]]"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "oddsratio, pvalue = scipy.stats.fisher_exact(cont_table)\n",
      "pvalue"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "0.54903578510541151"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this case we cannot reject the null hypothesis, as p > 0.05. There is no statistical evidence that the verb type affects the ouvertness of P/STIM."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 4. Positions of S, A and P"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "A_values = []\n",
      "P_values = []\n",
      "S_values = []\n",
      "for parent_node in clause_unit_nodes:\n",
      "    word_order = []\n",
      "    for gramm_node in ag.nodes_for_tier(\"grammatical_relation\", parent_node):\n",
      "        a_list = ag.annotations_for_tier(\"grammatical_relation\", gramm_node)\n",
      "        if len(a_list) > 0:\n",
      "            a_value = ag.annotation_value_for_annotation(a_list[0])\n",
      "            if a_value in verbs:\n",
      "                a_value = \"V\"\n",
      "            word_order.append(a_value)\n",
      "    if \"V\" in word_order:\n",
      "        v_index = word_order.index(\"V\")\n",
      "        if \"A\" in word_order:\n",
      "            A_values.append(word_order.index(\"A\") - v_index)\n",
      "        if \"P\" in word_order:\n",
      "            P_values.append(word_order.index(\"P\") - v_index)\n",
      "        if \"S\" in word_order:\n",
      "            S_values.append(word_order.index(\"S\") - v_index)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'clause_unit_nodes' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-35-091ba9ae0b6b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mP_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mS_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mparent_node\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclause_unit_nodes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mword_order\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mgramm_node\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes_for_tier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"grammatical_relation\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparent_node\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: name 'clause_unit_nodes' is not defined"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, axs = plt.subplots(1, 3, figsize=(14,4))\n",
      "axs[0].hist(S_values, range(min(S_values), max(S_values)+2))\n",
      "axs[0].set_title(\"Positions of S\")\n",
      "axs[1].hist(A_values, range(min(A_values), max(A_values)+2))\n",
      "axs[1].set_title(\"Positions of A\")\n",
      "axs[2].hist(P_values, range(min(P_values), max(P_values)+2))\n",
      "ret = axs[2].set_title(\"Positions of P\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Box plots of positions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.figure(figsize=(10,6))\n",
      "plt.boxplot([S_values, A_values, P_values])\n",
      "plt.title(\"Positions of S, A and P\")\n",
      "ret = plt.xticks([1, 2, 3], [\"S\", \"A\", \"P\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Plots by clause type"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "A_values = [[], []]\n",
      "P_values = [[], []]\n",
      "S_values = [[], []]\n",
      "clause_types = [\"m\", \"m.rs\", \"sub\", \"sub.rs\"]\n",
      "for parent_node in clause_unit_nodes:\n",
      "    word_order = []\n",
      "    clause_type = None\n",
      "    type_node = ag.nodes_for_tier(\"clause_type\", parent_node)\n",
      "    if len(type_node) > 0:\n",
      "        clause_type_ann = ag.annotations_for_tier(\"clause_type\", type_node[0])\n",
      "        clause_type = ag.annotation_value_for_annotation(clause_type_ann[0])\n",
      "    for gramm_node in ag.nodes_for_tier(\"grammatical_relation\", parent_node):\n",
      "        a_list = ag.annotations_for_tier(\"grammatical_relation\", gramm_node)\n",
      "        if len(a_list) > 0:\n",
      "            a_value = ag.annotation_value_for_annotation(a_list[0])\n",
      "            if a_value in verbs:\n",
      "                a_value = \"V\"\n",
      "            word_order.append(a_value)\n",
      "    if \"V\" in word_order and clause_type in clause_types:\n",
      "        ind = 0\n",
      "        if clause_type == \"sub\" or clause_type == \"sub.rs\":\n",
      "            ind = 1\n",
      "        v_index = word_order.index(\"V\")\n",
      "        if \"A\" in word_order:\n",
      "            A_values[ind].append(word_order.index(\"A\") - v_index)\n",
      "        if \"P\" in word_order:\n",
      "            P_values[ind].append(word_order.index(\"P\") - v_index)\n",
      "        if \"S\" in word_order:\n",
      "            S_values[ind].append(word_order.index(\"S\") - v_index)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, axs = plt.subplots(2, 3, figsize=(14,10))\n",
      "for ind in [0, 1]:\n",
      "    type_text = \"main\"\n",
      "    if ind == 1:\n",
      "        type_text = \"sub\"\n",
      "    axs[ind][0].hist(S_values[ind], range(min(S_values[ind]), max(S_values[ind])+2))\n",
      "    axs[ind][0].set_title(\"Positions of S in {0} clauses\".format(type_text))\n",
      "    axs[ind][1].hist(A_values[ind], range(min(A_values[ind]), max(A_values[ind])+2))\n",
      "    axs[ind][1].set_title(\"Positions of A {0} clauses\".format(type_text))\n",
      "    axs[ind][2].hist(P_values[ind], range(min(P_values[ind]), max(P_values[ind])+2))\n",
      "    ret = axs[ind][2].set_title(\"Positions of P {0} clauses\".format(type_text))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Box plots by clause type"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, axs = plt.subplots(1, 2, figsize=(14,6))\n",
      "for ind in [0, 1]:\n",
      "    type_text = \"main\"\n",
      "    if ind == 1:\n",
      "        type_text = \"sub\"\n",
      "\n",
      "    axs[ind].boxplot([S_values[ind], A_values[ind], P_values[ind]])\n",
      "    axs[ind].set_title(\"Positions of S, A and P in {0} clauses\".format(type_text))\n",
      "    ret = plt.xticks([1, 2, 3], [\"S\", \"A\", \"P\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}